{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "part2arunima.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOUvsf+VGS2ICTQ+vYGXrsq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arunima-22/CMT307/blob/master/part2code_%5B1655016%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3Ud9Ad5GrBy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "a0a4e270-fbbb-451c-d26b-4d0bd181c80e"
      },
      "source": [
        "#importing important modules\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import sklearn\n",
        "import operator\n",
        "import requests\n",
        "from string import punctuation\n",
        "from os import listdir\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "from collections import Counter\n",
        "from nltk.util import ngrams\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from sklearn.feature_selection import chi2, SelectKBest\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import time\n",
        "from scipy.sparse import coo_matrix, hstack\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from string import punctuation\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guAO1eD2IrBW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#loading neg reviews dev\n",
        "url = \"https://raw.githubusercontent.com/arunima-22/CMT307/master/imdb_dev_neg.txt\"\n",
        "response = requests.get(url)\n",
        "dev_neg = response.text.split(\"\\n\")\n",
        "\n",
        "#loading pos reviews dev\n",
        "url = \"https://raw.githubusercontent.com/arunima-22/CMT307/master/imdb_dev_pos.txt\"\n",
        "response = requests.get(url)\n",
        "dev_pos = response.text.split(\"\\n\")\n",
        "\n",
        "#loading neg reviews test\n",
        "url = \"https://raw.githubusercontent.com/arunima-22/CMT307/master/imdb_test_neg.txt\"\n",
        "response = requests.get(url)\n",
        "test_neg = response.text.split(\"\\n\")\n",
        "\n",
        "#loading pos reviews test\n",
        "url = \"https://raw.githubusercontent.com/arunima-22/CMT307/master/imdb_test_pos.txt\"\n",
        "response = requests.get(url)\n",
        "test_pos = response.text.split(\"\\n\")\n",
        "\n",
        "\n",
        "#loading neg reviews train\n",
        "url = \"https://raw.githubusercontent.com/arunima-22/CMT307/master/imdb_train_neg.txt\"\n",
        "response = requests.get(url)\n",
        "train_neg = response.text.split(\"\\n\")\n",
        "\n",
        "#loading pos reviews train\n",
        "url = \"https://raw.githubusercontent.com/arunima-22/CMT307/master/imdb_train_pos.txt\"\n",
        "response = requests.get(url)\n",
        "train_pos = response.text.split(\"\\n\")\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tGDJyRzyY98",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#initiating three datasets, each having positive and negative reviews\n",
        "new_dev=[]\n",
        "for pos_review in dev_pos:\n",
        "  new_dev.append((pos_review,1))\n",
        "for neg_review in dev_neg:\n",
        "  new_dev.append((neg_review,0))\n",
        "\n",
        "  new_test=[]\n",
        "for pos_review in test_pos:\n",
        "  new_test.append((pos_review,1))\n",
        "for neg_review in test_neg:\n",
        "  new_test.append((neg_review,0))\n",
        "\n",
        "  new_train=[]\n",
        "for pos_review in train_pos:\n",
        "  new_train.append((pos_review,1))\n",
        "for neg_review in train_neg:\n",
        "  new_train.append((neg_review,0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-MUo_Ep4vcZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "outputId": "af8334e1-f7ec-4667-ca78-3319873ea318"
      },
      "source": [
        "print (\"TRAINING SET\")\n",
        "print (\"Size training set: \"+str(len(new_train)))\n",
        "for example in new_train[:1]:\n",
        "    print (example)\n",
        "print (\"    \\n-------\\n\")\n",
        "print (\"TEST SET\")\n",
        "print (\"Size development set: \"+str(len(new_dev)))\n",
        "for example in new_dev[:1]:\n",
        "  print (example)\n",
        "print (\"    \\n-------\\n\")\n",
        "print (\"DEVELOPMENT SET\")\n",
        "print (\"Size test set: \"+str(len(new_test)))\n",
        "for example in new_test[:1]:\n",
        "  print (example)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAINING SET\n",
            "Size training set: 15002\n",
            "('For fans of Chris Farley, this is probably his best film. David Spade plays the perfect cynical, sarcastic yin to Farley\\'s \"Baby Huey\" yang. Farley achieves strokes of comic genius in his monologues, like the \"Let\\'s say you\\'re driving along the road with your family...\" bit, the \"Jo-Jo the Idiot Circus Boy with a pretty new pet, (his possible sale)\" speech, or the \"Glue-sniffing Guarantee fairy\" brake pad sale. The sappy moments in the film contrast sharply with Farley and Spade\\'s shenanigans. Even after many viewings, it\\'s still fun to see Farley pour everything he had into the role. \"Richard, what\\'s HAPPENING to me?!?!\"', 1)\n",
            "    \n",
            "-------\n",
            "\n",
            "TEST SET\n",
            "Size development set: 5002\n",
            "('After 10 viewings in 20 years I too think this was the Crazy Gang\\'s best effort on film, with more cohesion in the plot than their next best, \"Alf\\'s Button Afloat\". They were indeed a crazy trio of double acts thrown together mainly on stage, sometimes in front of royalty, until Chesney Allen retired in the \\'40\\'s through \"ill-health\". He outlived them all by years. Apparently they were just as mad outside \"work\", regularly playing practical jokes on one another.<br /><br />The Six Wonder Boys troupe head for I\\'ll-Get-Her-To-Tell-Me (Alaska) to dig for the gold that was being found there. It seemed a better idea than going to Mansfield ... because they\\'d been there. When they get to Red Gulch they find their information was a mere 40 years out of date - they thought that the chips that were in the guilty newspaper they\\'d read tasted funny. But by then it doesn\\'t matter as they\\'ve all fallen in love with Snow White and want to help her grandad find his long lost stash of gold. Baddie Bill \"M\" McGrew wants it himself however.<br /><br />The number of verbal and visual puns is astonishing, but most of them will probably only make sense(?) to Brits and ex-pats interested in seeing \\'30\\'s British b&w comedies. Imho nearly all of the gags and routines work, including the Gold If patter between Bud & Chesney and the \"Whistle While You Work\" pastiche - even the \"Always Getting Our Man\" Mountie inserts. A marvellous little film, in a rather tired looking condition but utterly recommended.', 1)\n",
            "    \n",
            "-------\n",
            "\n",
            "DEVELOPMENT SET\n",
            "Size test set: 5002\n",
            "('This is the greatest movie if you want inspiration on following your heart and never giving up on your dream. Elizabeth Taylor is Velvet and in her prime (of her childhood, at least), Mickey Rooney is a cynical friend who eventually becomes her trainer and they go off to the Grand National steeplechase with her beloved horse \"the Pi\"--short for \"Pirate\"--only to have Velvet become the jockey and have a chance at victory. To those of you who have not seen it yet, I won\\'t give away the ending but you should see it and once you do you\\'ll love it. Notice a very young Angela Lansbury as Velvet\\'s eldest sister.', 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssQzwAnZwtjV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "2852a9b9-ae85-4be7-f4b2-11520474184c"
      },
      "source": [
        "print (\"Positive reviews:\\n\")\n",
        "for pos_review in train_pos[:5]:\n",
        "  print (pos_review)\n",
        "print (\"\\n   ------\\n\")  \n",
        "print (\"Negative reviews:\\n\")\n",
        "for neg_review in train_neg[:5]:\n",
        "  print (neg_review)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive reviews:\n",
            "\n",
            "For fans of Chris Farley, this is probably his best film. David Spade plays the perfect cynical, sarcastic yin to Farley's \"Baby Huey\" yang. Farley achieves strokes of comic genius in his monologues, like the \"Let's say you're driving along the road with your family...\" bit, the \"Jo-Jo the Idiot Circus Boy with a pretty new pet, (his possible sale)\" speech, or the \"Glue-sniffing Guarantee fairy\" brake pad sale. The sappy moments in the film contrast sharply with Farley and Spade's shenanigans. Even after many viewings, it's still fun to see Farley pour everything he had into the role. \"Richard, what's HAPPENING to me?!?!\"\n",
            "Fantastic, Madonna at her finest, the film is funny and her acting is brilliant. It may have been made in the 80's but it has all the qualities of a modern Hollywood Block-buster. I love this film and i think its totally unique and will cheer up any droopy person within a matter of minutes. Fantastic.\n",
            "From a perspective that it is possible to make movies that are not offensive to people with strong moral values, this one is definitely worthwhile. This is the second Bruce Willis film in a row that manages to tell its story with no nudity, off-color humor, profanity, or gratuitous violence. (I refer of course to The Sixth Sense.) Both movies are engaging on more than one level. This one is appropriate for children as well, although as others have pointed out, it isn't a flick FOR kids. <br /><br />I was bothered that the time travel device that drives this plot is never explained, except that we know Russell himself initiates it as a 70 year old. Also, why does his dying mother have to come to school to get him when he wins the fight; why, if as his older self says, he has to fight that kid again and again for the next few years does his mother not have to come and get him every time, and why he doesn't learn to kick butt in the process. I also found the score rather annoying and not always appropriate to the action on stage. <br /><br />Good use of the red plane as metaphor, however.\n",
            "What is often neglected about Harold Lloyd is that he was an actor. Unlike Chaplin and Keaton, Lloyd didn't have the Vaudeville/Music Hall background and he wasn't a natural comedian. He came to Hollywood to act; and he discovered he had a knack for acting funny -- first in shorts, then in features. He made a name for himself as \"Lonesome Luke\", a Chaplin knock-off; with the \"glasses character\" that made him the all-American boy rather than a grotesque, Lloyd found his stride and his movies became some of the best produced during the silent era.<br /><br />He developed a reputation as a \"daredevil\" in some shorts, and retained this in some of his best movies (\"Safety Last\", \"For Heaven's Sake\", \"Girl Shy\"). He was more popular than either Chaplin or Keaton during the twenties and he became very rich before the advent of sound.<br /><br />The first sound movies were often disasters. To get the most out of their \"sound\", too much dialog was used in many movies.<br /><br />Lloyd's acting skills were, after two decades, geared for silents. He didn't have a bad voice; its high pitch suited his \"glasses\" character. And his sound films weren't the unqualified disasters of legend. Yet silent movies had been raised to a high art (especially Lloyd's, which did not stint on budget and were extremely well-crafted); with the introduction of talkies movies had to learn to walk again and they made some missteps.<br /><br />Though he tried to move with the times and embraced sound, Lloyd's best bits from his early (overly talky) talkies were still visual -- such as the scene in \"Movie Crazy\" where he appears to be riding in a swank car, but actually \"hitched a ride\" on his bicycle.<br /><br />Trying to recapture the daredevil antics that made him famous, as he did in \"Feet First\", was misstep. (In \"Safety Last\", his best movie and the one that, deservedly or not, shoved Lloyd in the box as a \"daredevil comic\", he played a determined young man, climbing to the top. \"Safety Last\" had a natural structure that ascended to his character's scaling the side of the building. He was obviously afraid, but his fear added to the humor. In \"Feet First\", he arrived in a precarious building-scaling position by accident; his frantic cries for help detracted from the humor. His character was pathetic and cringing, aspiration to save his neck -- possibly an accurate statement of the 1930s, but not amusing).<br /><br />Harold Lloyd was not mired in the past, like some wacky Norma Desmond. He embraced sound and tried to take his movies in different directions, growing and changing with the industry. When \"Feet First\" failed he left the daredevil business and made a satire on the talking movie industry, \"Movie Crazy\". Just as he had to flounder through many movies as \"Lonesome Luke\" before carving his place in movie history with the glasses character, he had tried several directions in sound movies before hitting his stride in sound, which he did with \"The Catspaw\".<br /><br />In \"The Catspaw\" he plays a missionary's son reared in China who unwittingly gets elected mayor as a front for corrupt political interests. When he finds out the truth, he sets himself the task of cleaning up the town. Only in his early forties, Lloyd could still act the brash young man.<br /><br />Yet \"The Catspaw\" was another box-office failure, and Lloyd made only three more movies, including \"The Milky Way\". Of his chief competitors, Chaplin still had silent movies in him and Keaton was hopelessly mismanaged. \"The Catspaw\" and \"The Milky Way\" suggest Lloyd might have mastered sound comedy if he had been a little younger, or if audiences had given him the benefit of the doubt after his early sound fiascoes.<br /><br />Though the movie has been unfairly maligned about the way Lloyd's character cleaned up the town, it suits him. From his days in \"shorts\" Lloyd wanted to scare his audience, and the climax of \"The Catspaw\" achieved it yet again, in a surprising way; until the trick is revealed it appears gruesome, and then come the laughs.<br /><br />Viewed as a product of its time, \"The Catspaw\" is charming and funny. A very well-written sound comedy, well-acted by Lloyd. Directed by Sam Taylor, its curious blend of drama and sly humor make it look almost like a Frank Capra or Preston Sturges comedy.\n",
            "You'll either love or hate movies such as this thriller set inside a lonesome asylum in a far off lonesome land. It's not so much of a horror show, but a concoction of frightening imageries and wackozoid mental patients. \"Scream\" is the best term to use in what was obviously a popular drive-in classic noted for some strange and wicked behaviors. Notice the \"judge\", who's about to put on the ax from behind the doctor! Brr-r-r-r!!! Not much else can be described here other than some bloody tasty goodness, but when you get a chance, remember the familiar old saying by the hag lady: \"Get out! Get out! And never ever come back!\". Don't you wish you haven't looked in the basement?\n",
            "\n",
            "   ------\n",
            "\n",
            "Negative reviews:\n",
            "\n",
            "A terrible deception: controversial film, winner of the Teddy in Berlin 2003, Mil nubes de paz turned out to be a fiasco. The actors are all reciting (well, they are not exactly actors); the film tried to be a high bet but ends up being a doubtful bet: it stays in the superficiality of two guys kissing and a guy whose lover is gone; it has no purpose: nothing to do with the homo-sexuality presented in other films (e.g. Before Night Falls (2000) by Julian Schnabel). Technically the only thing that works is the photography; otherwise, the camera is put in strange angles (to make it more `art-film') and the whole film runs in a black and white atmosphere. The film is so pretentious that bothers. I mean, it's good to be pretentious when you have talent to support it. Or maybe it is that it's so art-cinema that it's incomprehensible. The story flows slowly, slowly, slowly. To me, more form than essence. Superb edition? It was good. Superb direction? Don't think so: the film is weak. It was an interesting project. It's a shame. It's a flaw. One star out of four.\n",
            "Well I guess I know the answer to that question. For the MONEY! We have been so bombarded with Cat In The Hat advertising and merchandise that we almost believe there has to be something good about this movie. I admit, I thought the trailers looked bad, but I still had to give it a chance. Well I should have went with my instincts. It was a complete piece Hollywood trash. Once again proving that the average person can be programed into believing anything they say is good, must be good. Aside from the insulting fact that the film is only about 80 minutes long, it obviously started with a moth eaten script. It's chock full of failed attempts at senseless humor, and awful pastel sceneries. It jumps all over the universe with no destination nor direction. This is then compounded with, ............................yes I'll say it, BAD ACTING! I couldn't help but feel like I was watching \"Coffee Talk\" on SNL every time Mike Myers opened his mouth. Was the Cat intended to be a middle aged Jewish woman? Spencer Breslin and Dakota Fanning were no prize either, but Mr. Myers should disappear under a rock somewhere until he's ready to make another Austin Powers movie. F-, no stars, 0 on a scale of 1-10. Save your money!\n",
            "I really liked the movie 'The Emporer's New Groove', but watching this was like coming home and seeing your wife having \"relations\" with a llama. Seriously, this movie was bad. It's like Club Dread after Super Troopers. I am supposed to write 10 lines, but I don't even know what else to say. I laughed a couple of times, but only because I was drinking. A movie like that should at least be funny when your drunk. It was not. Maybe llamas are just funny and regular cartoon people aren't. Either way, just stick with The Emporer's New Groove if you want a funny, cartoon, llama-themed movie. Line 10 is this line right here.\n",
            "Thats what this movie really takes. A big piece of cheeze. This movie is about a sister and brother Bonnie and Clyde type of duo that creates their own party line in order to lure their victims in and trap them and kill them. But for what reason? Just for the fun of getting away with it? In comes Richard Hatch who comes across as a wishy washy ladies man. A real BAD version of a ladies man. And he gets involved with finding who's behind all the killings across LA. He finally meets a teenager who helps him find the killer and rest is for your fun and amusement. But there are parts in this film that really get me going like the scene with Lief Garret dressed in his mothers wedding gown acting like a sissy in front of his sister telling her that he needs her and can't live without her and watching as she slaps him across the face dominateing him. I can't believe that was Lief!!! Well, I guess I could. But it's worth watching but only to see one of Garrets worst films that he ever did.\n",
            "I was looking for a documentary of the same journalistic quality as Frontline or \"Fog of War\" (by Errol Morris). Instead I was appalled by this shallow and naive account of a very complex and disturbing man and his regime: Alberto Fujimori. This movie should be called \"The return of Fujimori\". The director presumes she made a \"perfect\" movie because alienates both pro and anti-Fujimori factions when in fact it is a very biased and unprofessional piece of work. <br /><br />The movie has few crucial facts wrong: <br /><br />1) She uses the so called \"landslide\" election of 1995 in which Fujimori was re-elected with 65% of the vote, as an example of the massive popular support of Fujimori. But we all now know to be the fruit of a very organized electoral fraud.<br /><br />2) The movie states that Sendero Luminoso (Shining Path) killed 60,000 people. In fact, the Truth Commission's final report states that there were 69,280 deaths due to political violence in Peru. 33% of those were caused by SL. That leaves the other 67% in the hands of the police, military and other groups. The fact that she uses the same misleading information that Fujimori has been using for 10 years it is another example of how terrible this movie is. <br /><br />For any person with some education on Peruvian politics and history, Fujimori is clearly a consummated manipulator, a delusional character and remorseless egomaniac. His regime was very far from being democratic. He is still a menace to Peruvians. Despite these facts the director lets Fujimori tell the story. Not only on how he wants the camera to be positioned but the narrative and direction of the film seem to be part of his political agenda. He always seems to have the last word. There are no journalistic \"cojones\", just soft questions and unchallenged remarks. Where is Oriana Fallaci when we need her? The director, when questioned after the screening, didn't hide the fact that she was deeply impressed by Fujimori, his charm and intelligence. Yes, she has been definitely charmed by him, and you can tell by looking at this film. It's obvious she has a very hard time to digest the multitude of facts that point towards his responsibility on the corruption, murder and deception that took place. She assured the gasping audience that Fujimori was really a \"patriot\" when few moments earlier, one of the leading Peruvian journalists was very adamant in telling us that Fujimori was, above all, a \"traitor\". She went on to say that despite all the accusations not \"a single dollar\" was found on any bank account on his name, etc, etc. It was like hearing again the same gang of ruthless thugs that ruled the country for 10 years defending their master. It was a sad moment for journalism.<br /><br />This film makes injustice to history. It is an insult to hundreds of dead people, disappeared or unjustly incarcerated by Fujimori's regime. No wonder she later confessed that all the Peruvian intellectuals she befriended while making the movie felt betrayed by it. Unbiased? The words \"oportunistic\", \"naïve\" and \"denial\" come to my mind instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8znmODgI2ShA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "0dfc713b-6c42-455b-ce78-17c5205c399b"
      },
      "source": [
        "\n",
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "def get_list_tokens(string):\n",
        "  sentence_split=nltk.tokenize.sent_tokenize(string)\n",
        "  list_tokens=[]\n",
        "  for sentence in sentence_split:\n",
        "    list_tokens_sentence=nltk.tokenize.word_tokenize(sentence)\n",
        "    for token in list_tokens_sentence:\n",
        "      list_tokens.append(lemmatizer.lemmatize(token).lower())\n",
        "  return list_tokens\n",
        "\n",
        "# First, we get the stopwords list from nltk\n",
        "stopwords=set(nltk.corpus.stopwords.words('english'))\n",
        "# We can add more words to the stopword list, like punctuation marks\n",
        "stopwords.add(\".\")\n",
        "stopwords.add(\",\")\n",
        "stopwords.add(\"--\")\n",
        "stopwords.add(\"``\")\n",
        "stopwords.add(\"#\")\n",
        "stopwords.add(\"@\")\n",
        "stopwords.add(\":\")\n",
        "stopwords.add(\"'s\")\n",
        "stopwords.add(\"’\")\n",
        "stopwords.add(\"...\")\n",
        "stopwords.add(\"n't\")\n",
        "stopwords.add(\"'re\")\n",
        "stopwords.add(\"'\")\n",
        "stopwords.add(\"-\")\n",
        "stopwords.add(\";\")\n",
        "stopwords.add(\"/\")\n",
        "stopwords.add(\">\")\n",
        "stopwords.add(\"<\")\n",
        "stopwords.add(\"br\")\n",
        "stopwords.add(\"(\")\n",
        "stopwords.add(\")\")\n",
        "stopwords.add(\"''\")\n",
        "stopwords.add(\"&\")\n",
        "\n",
        "# Now we create a frequency dictionary with all words in the dataset\n",
        "\n",
        "\n",
        "dict_word_frequency={}\n",
        "for pos_review in train_pos:\n",
        "  sentence_tokens=get_list_tokens(pos_review)\n",
        "  for word in sentence_tokens:\n",
        "    if word in stopwords: continue\n",
        "    if word not in dict_word_frequency: dict_word_frequency[word]=1\n",
        "    else: dict_word_frequency[word]+=1\n",
        "for neg_review in train_neg:\n",
        "  sentence_tokens=get_list_tokens(neg_review)\n",
        "  for word in sentence_tokens:\n",
        "    if word in stopwords: continue\n",
        "    if word not in dict_word_frequency: dict_word_frequency[word]=1\n",
        "    else: dict_word_frequency[word]+=1\n",
        "      \n",
        "# Now we create a sorted frequency list with the top 1000 words, using the function \"sorted\". Let's see the 15 most frequent words\n",
        "sorted_list = sorted(dict_word_frequency.items(), key=operator.itemgetter(1), reverse=True)[:1000]\n",
        "i=0\n",
        "for word,frequency in sorted_list[:15]:\n",
        "  i+=1\n",
        "  print (str(i)+\". \"+word+\" - \"+str(frequency))\n",
        "  \n",
        "# Finally, we create our vocabulary based on the sorted frequency list \n",
        "vocabulary=[]\n",
        "for word,frequency in sorted_list:\n",
        "  vocabulary.append(word)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1. / - 59704\n",
            "2. > - 59628\n",
            "3. < - 59572\n",
            "4. br - 59548\n",
            "5. 's - 36104\n",
            "6. movie - 29647\n",
            "7. wa - 29577\n",
            "8. film - 26929\n",
            "9. ) - 21211\n",
            "10. ( - 20708\n",
            "11. '' - 19859\n",
            "12. `` - 19693\n",
            "13. n't - 19639\n",
            "14. one - 15987\n",
            "15. ! - 14847\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wD5dqcb3H2x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_vector_text(list_vocab,string):\n",
        "  vector_text=np.zeros(len(list_vocab))\n",
        "  list_tokens_string=get_list_tokens(string)\n",
        "  for i, word in enumerate(list_vocab):\n",
        "    if word in list_tokens_string:\n",
        "      vector_text[i]=list_tokens_string.count(word)\n",
        "  return vector_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uoxJdlO3Zwb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_vocabulary(training_set, num_features): # Function to retrieve vocabulary\n",
        "  dict_word_frequency={}\n",
        "  for instance in training_set:\n",
        "    sentence_tokens=get_list_tokens(instance[0])\n",
        "    for word in sentence_tokens:\n",
        "      if word in stopwords: continue\n",
        "      if word not in dict_word_frequency: dict_word_frequency[word]=1\n",
        "      else: dict_word_frequency[word]+=1\n",
        "  sorted_list = sorted(dict_word_frequency.items(), key=operator.itemgetter(1), reverse=True)[:num_features]\n",
        "  vocabulary=[]\n",
        "  for word,frequency in sorted_list:\n",
        "    vocabulary.append(word)\n",
        "  return vocabulary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-8_xSch35d3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_svm_classifier(training_set, vocabulary): # Function for training our svm classifier\n",
        "  X_train=[]\n",
        "  Y_train=[]\n",
        "  for instance in new_train:\n",
        "    vector_instance=get_vector_text(vocabulary,instance[0])\n",
        "    X_train.append(vector_instance)\n",
        "    Y_train.append(instance[1])\n",
        "  # Finally, we train the SVM classifier \n",
        "  svm_clf=sklearn.svm.SVC(kernel=\"linear\",gamma='auto')\n",
        "  svm_clf.fit(np.asarray(X_train),np.asarray(Y_train))\n",
        "  return svm_clf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Lp8SueR5AWo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocabulary=get_vocabulary(new_train, 1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbAqVF2v5jnz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "svm_clf=train_svm_classifier(new_train, vocabulary)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaPvoezzBZoY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test=[]\n",
        "Y_test=[]\n",
        "for instance in new_test:\n",
        "  vector_instance=get_vector_text(vocabulary,instance[0])\n",
        "  X_test.append(vector_instance)\n",
        "  Y_test.append(instance[1])\n",
        "X_test=np.asarray(X_test)\n",
        "Y_test_gold=np.asarray(Y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9UYTCxuByhb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTr15DOAB1qH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_text_predictions=svm_clf.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3eKdpxnCFQu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import precision_score,recall_score,f1_score,accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyrhbVs5CJL_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "61dad660-a7b9-40e8-8ead-5ae1bc128ea3"
      },
      "source": [
        "precision=precision_score(Y_test_gold, Y_text_predictions, average='macro')\n",
        "recall=recall_score(Y_test_gold, Y_text_predictions, average='macro')\n",
        "f1=f1_score(Y_test_gold, Y_text_predictions, average='macro')\n",
        "accuracy=accuracy_score(Y_test_gold, Y_text_predictions)\n",
        "\n",
        "print (\"Precision: \"+str(round(precision,3)))\n",
        "print (\"Recall: \"+str(round(recall,3)))\n",
        "print (\"F1-Score: \"+str(round(f1,3)))\n",
        "print (\"Accuracy: \"+str(round(accuracy,3)))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.848\n",
            "Recall: 0.848\n",
            "F1-Score: 0.848\n",
            "Accuracy: 0.848\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRVuHKB-Hbh0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "29155761-c50c-4429-d079-ddf3c34847bb"
      },
      "source": [
        "\n",
        "Y_dev=[]\n",
        "for instance in new_dev:\n",
        "  Y_dev.append(instance[1])\n",
        "Y_dev_gold=np.asarray(Y_dev)\n",
        "\n",
        "# Now we can train our three models with the different number of features, and test each of them in the dev set\n",
        "list_num_features=[250,500,750,1000]\n",
        "best_accuracy_dev=0.0\n",
        "for num_features in list_num_features:\n",
        "  # First, we get the vocabulary from the training set and train our svm classifier\n",
        "  vocabulary=get_vocabulary(new_train, num_features)  \n",
        "  svm_clf=train_svm_classifier(new_train, vocabulary)\n",
        "  # Then, we transform our dev set into vectors and make the prediction on this set\n",
        "  X_dev=[]\n",
        "  for instance in new_dev:\n",
        "    vector_instance=get_vector_text(vocabulary,instance[0])\n",
        "    X_dev.append(vector_instance)\n",
        "  X_dev=np.asarray(X_dev)\n",
        "  Y_dev_predictions=svm_clf.predict(X_dev)\n",
        "  # Finally, we get the accuracy results of the classifier\n",
        "  accuracy_dev=accuracy_score(Y_dev_gold, Y_dev_predictions)\n",
        "  print (\"Accuracy with \"+str(num_features)+\": \"+str(round(accuracy_dev,3)))\n",
        "  if accuracy_dev>=best_accuracy_dev:\n",
        "    best_accuracy_dev=accuracy_dev\n",
        "    best_num_features=num_features\n",
        "    best_vocabulary=vocabulary\n",
        "    best_svm_clf=svm_clf\n",
        "print (\"\\n Best accuracy overall in the dev set is \"+str(round(best_accuracy_dev,3))+\" with \"+str(best_num_features)+\" features.\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy with 250: 0.783\n",
            "Accuracy with 500: 0.834\n",
            "Accuracy with 750: 0.845\n",
            "Accuracy with 1000: 0.846\n",
            "\n",
            " Best accuracy overall in the dev set is 0.846 with 1000 features.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7igFH1oWs-A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "272691a5-029f-492d-92d0-29973d8c0cbc"
      },
      "source": [
        "vectorizer = TfidfVectorizer(ngram_range=(1,3),max_features=2000)\n",
        "matrix = vectorizer.fit_transform(np.asarray([i[0] for i in new_train]))\n",
        "X_train = matrix.toarray()\n",
        "Y_train=[i[1] for i in new_train]\n",
        "\n",
        "svm_clf=sklearn.svm.SVC(kernel=\"linear\",gamma='auto')\n",
        "svm_clf.fit(np.asarray(X_train),np.asarray(Y_train))\n",
        "\n",
        "X_dev = vectorizer.transform([i[0] for i in new_dev]).toarray()\n",
        "predictions = svm_clf.predict(X_dev)\n",
        "print(sklearn.metrics.classification_report(predictions,[i[1] for i in new_dev]))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.88      0.87      2427\n",
            "           1       0.88      0.86      0.87      2575\n",
            "\n",
            "    accuracy                           0.87      5002\n",
            "   macro avg       0.87      0.87      0.87      5002\n",
            "weighted avg       0.87      0.87      0.87      5002\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ci87btjgs38m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#the chi-squared test method is used. This method basically removes the features that appear to be irrelevant to a given class (in our case positive or negative)\n",
        "vectorizer_f = TfidfVectorizer(ngram_range=(1,2),max_features=5000)\n",
        "X_train = vectorizer_f.fit_transform([i[0] for i in new_train]).toarray()\n",
        "Y_train = np.asarray([i[1] for i in new_train])\n",
        "\n",
        "X_feature_best = SelectKBest(chi2, k=500).fit(X_train, Y_train)\n",
        "X_train_feature_best = X_feature_best.transform(X_train)\n",
        "\n",
        "X_test = vectorizer_f.transform([i[0] for i in new_test]).toarray()\n",
        "X_test_feature_best =  X_feature_best.transform(X_test)\n",
        "\n",
        "Y_test = np.asarray([i[1] for i in new_test])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEfeq6suusqo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "b2b15ae4-c123-4a8c-a331-de276a410de6"
      },
      "source": [
        "#final accuracy, recall, precision and f-measure.\n",
        "new_svm_clf_sentanalysis_=sklearn.svm.SVC(kernel=\"linear\",gamma='auto')\n",
        "new_svm_clf_sentanalysis_.fit(np.asarray(X_train_feature_best),Y_train)\n",
        "predictions_feature_best = new_svm_clf_sentanalysis_.predict(X_test_feature_best)\n",
        "print(sklearn.metrics.classification_report(predictions_feature_best,Y_test))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.89      0.86      2376\n",
            "           1       0.89      0.85      0.87      2626\n",
            "\n",
            "    accuracy                           0.87      5002\n",
            "   macro avg       0.87      0.87      0.87      5002\n",
            "weighted avg       0.87      0.87      0.87      5002\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}